import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Goal of this project:
# I want to figure out how much should a graduate be paid, based on their productivity
# Then find out if their predicted wages match up to their actual wages

# Time to prepare my Wages Data Set

# Obtaining the data for wages
wages_df = pd.read_csv("wages.csv")

# Focusing only on the 3 rows of data we are interested in
wages_df = pd.DataFrame(wages_df.iloc[9:11])

# Making the data labels into column names instead of row names
wages_df = wages_df.transpose()

# Dropping a redundant column "Unnamed"
wages_df = wages_df.reset_index(drop=True)

# Renaming the columns for better readability
wages_df = wages_df.set_axis(['Year', 'Median Monthly Income'], axis='columns')

# Dropping the duplicate column names
wages_df = wages_df.drop(index=0)

# Standardising all data values into integers
wages_df = wages_df.astype(int)
wages_df = wages_df.sort_values(by='Year')
# Sanity check
print(wages_df)

# Time to Prepare my Productivity Data Set

# Obtaining the data for productivity
productivity_df = pd.read_csv("productivity.csv")

# Focusing on the actual data in the file
productivity_df = pd.DataFrame(productivity_df.iloc[9:11])

# Making the data labels into column names instead of row names
productivity_df = productivity_df.transpose()

# Dropping a redundant column "Unnamed"
productivity_df = productivity_df.reset_index()

# Renaming the columns for better readability
productivity_df = productivity_df.set_axis(['Annual', 'Quarterly', 'Composite Leading Index'], axis='columns')

# Dropping the duplicate column names
productivity_df = productivity_df.drop(index=0)

# Sanity check
print(productivity_df)

# Inputting the years into the empty Annual Column
for n in range(1, len(productivity_df), 4):
    productivity_df['Annual'][n-1:n+3] = int(2022 - (n-1)/4)

# Prepping the Composite Leading Index Column as float values for mean calculation
productivity_df['Composite Leading Index'] = productivity_df['Composite Leading Index'].astype(float)

# Sanity check
print(productivity_df)

# Creating a new DataFrame to hold the mean values of productivity
prod_annual = productivity_df.groupby('Annual')
prod_annual = prod_annual.size().to_frame(name='counts').join(prod_annual.agg({'Composite Leading Index': 'mean'}).rename(columns={'Composite Leading Index': 'Annual Composite Leading Index'}))
prod_annual = prod_annual.reset_index()
prod_annual = pd.DataFrame(prod_annual)

# Renaming the columns and dropping the redundant Count Column for better readability
prod_annual = prod_annual.rename(columns={"Annual": "Year"})
prod_annual = prod_annual.drop(columns=['counts'])

# Sanity Check
print(prod_annual)

# Obtaining the data for graduates
graduates_df = pd.read_csv("graduates.csv")

# Focusing only on the rows of data we are interested in
graduates_df = pd.DataFrame(graduates_df.iloc[9:42])

# Making the data labels into column names instead of row names
graduates_df = graduates_df.transpose()

# Dropping a redundant column "Unnamed"
graduates_df = graduates_df.reset_index(drop=True)

# Renaming the columns for better readability and dropping duplicate names
graduates_df = graduates_df.set_axis(graduates_df.iloc[0], axis='columns')
graduates_df = graduates_df.rename(columns={"Data Series": "Year"})
graduates_df = graduates_df.drop(index=0)
print(graduates_df)

# Filling the missing data with 0
graduates_df = graduates_df.replace('na', 0)

# Standardising all values to be of integer values
graduates_df = graduates_df.astype(int)
graduates_df.sort_values(by='Year')
# Sanity check
print(graduates_df)

# Time to do some data analysis

# First, we need to merge all 3 data sets into one for convenience
# It also conveniently picks the subset of years that exist on all 3 data sets
data = pd.merge(prod_annual, wages_df, on='Year')
data = pd.merge(graduates_df, data, on='Year')
print(data)

# Labelling the relevant variables for future analysis
productivity = data['Annual Composite Leading Index']
wages = data['Median Monthly Income']
year = data['Year']
male_graduates = data['Males']
female_graduates = data['Females']

# Let's find what is the relationship between wages and productivity

fig, axs = plt.subplots(1, 2, figsize=(10, 5))
# Plot the first scatterplot in the first subplot
sns.lineplot(y=productivity, x=year, ax=axs[0])
axs[0].set_title('Productivity Over Time')

# Plot the second scatterplot in the second subplot
sns.lineplot(y=wages, x=year, ax=axs[1])
axs[1].set_title('Wages Over Time')
plt.show()

# predicting variable will be productivity, and predicted variable will be wages
sns.jointplot(x= productivity, y= wages, kind="reg")
plt.show()

# Perform regression analysis
X = productivity.values.reshape(-1,1)
y = wages
X = (X - X.mean()) / X.std()
model = LinearRegression().fit(X, y)
print("\nCoefficients:\n[Productivity as predictor & Wages as predictand: ", model.coef_)

# START OF TRAINING DATASET TO PREDICT WAGES BASED ON PRODUCTIVITY

# Create empty lists to store RMSE and R2 scores for each fold
rmse_wages_list = []
r2_wages_list = []

kf = KFold(n_splits=5, shuffle=True, random_state=42)
f, axes = plt.subplots(5, 2, figsize=(18, 24))
count = 0

for train_index, test_index in kf.split(X):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    # Perform regression analysis on the training set
    model_wages = LinearRegression()
    model_wages = model_wages.fit(X_train, y_train)

    # Predict productivity for the testing data
    y_pred_test = model_wages.predict(X_test)

    y_pred_train = model_wages.predict(X_train)

    # Evaluate the model on the testing set
    r2_wages = model_wages.score(X_test, y_test)

    print(f"\nR^2 score: {r2_wages:.2f}")

    # Calculate the mean squared error for this fold
    mse_wages = mean_squared_error(y_test, y_pred_test)
    rmse_wages = np.sqrt(mse_wages)

    # Append RMSE and R2 scores to the lists
    rmse_wages_list.append(rmse_wages)
    r2_wages_list.append(r2_wages)

    # Calculate the average RMSE and R2 score
    rmse_ave = np.mean(rmse_wages_list)
    score_ave = np.mean(r2_wages_list)

    # Print the mean squared error for this fold
    print("Root Mean Squared Error:", rmse_wages.round(2))

    sns.regplot(x=X_train, y=y_train, label='Train', ax=axes[count, 0])
    sns.regplot(x=X_test, y=y_test, label='Test', ax=axes[count, 1])

    axes[count, 0].set_xlabel('Productivity vs Wages (Train)')
    axes[count, 1].set_xlabel('Productivity vs Wages (Test)')
    count += 1

print("\nGoodness of Fit of Productivity against Wages:")
print("Average Explained Variance (R^2) \t:", score_ave.round(2))
print("Average Root Mean Squared Error (RMSE) \t: $", rmse_ave.round(2), sep='')

# THIS IS THE END FOR PRODUCTIVITY VS WAGES

# THIS IS THE START FOR GRADUATE PROFILE VS PRODUCTIVITY

fig, axs = plt.subplots(1, 2, figsize=(10, 5))

# Plot the first scatterplot in the first subplot
sns.lineplot(y=female_graduates, x=year, ax=axs[0])
axs[0].set_title('Number of Female Graduates Over Time')

# Plot the second scatterplot in the second subplot
sns.lineplot(y=male_graduates, x=year, ax=axs[1])
axs[1].set_title('Number of Male Graduates Over Time')
plt.show()

# Perform regression analysis
X = data[['Females', 'Males']]
y = productivity
X = (X - X.mean()) / X.std()
reg = LinearRegression().fit(X, y)
print("\nCoefficients:\n[Female Graduates | Male Graduates]\n", reg.coef_)

fig, axs = plt.subplots(1, 2, figsize=(10, 5))

# Plot the first scatterplot in the first subplot
sns.lineplot(y=productivity, x=female_graduates, ax=axs[0])
axs[0].set_title('Female productivity')

# Plot the second scatterplot in the second subplot
sns.lineplot(y=productivity, x=male_graduates, ax=axs[1])
axs[1].set_title('Male productivity')
plt.show()

# Create empty lists to store RMSE and R2 scores for each fold
rmse_list = []
r2_list = []

kf = KFold(n_splits=5, shuffle=True, random_state=42)

for train_index, test_index in kf.split(X):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]

    # Perform regression analysis on the training set
    reg = LinearRegression()
    reg = reg.fit(X_train, y_train)

    # Predict productivity for the testing data
    y_pred = reg.predict(X_test)

    # Evaluate the model on the testing set
    r2 = reg.score(X_test, y_test)

    print(f"\nR^2 score: {r2:.2f}")

    # Calculate the mean squared error for this fold
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)

    # Append RMSE and R2 scores to the lists
    rmse_list.append(rmse)
    r2_list.append(r2)

    # Calculate the average RMSE and R2 score
    rmse_ave = np.mean(rmse_list)
    score_ave = np.mean(r2_list)

    # Print the mean squared error for this fold
    print("Root Mean Squared Error:", rmse.round(2))

print("\nGoodness of Fit of Productivity against Graduate Profile:")
print("Average Explained Variance (R^2) \t:", score_ave.round(2))
print("Average Root Mean Squared Error (RMSE) \t:", rmse_ave.round(2))
